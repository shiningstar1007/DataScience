{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "import optuna.integration.lightgbm as lgb\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (16, 8)\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('./input')\n",
    "feature_dir = Path('./input')\n",
    "val_dir = Path('./input/val')\n",
    "tst_dir = Path('./input/tst')\n",
    "sub_dir = Path('./input/sub')\n",
    "\n",
    "trn_file = data_dir / 'train.csv'\n",
    "tst_file = data_dir / 'test.csv'\n",
    "sample_file = data_dir / 'sample_submission.csv'\n",
    "\n",
    "target_col = 'class'\n",
    "n_fold = 5\n",
    "n_class = 3\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_name = 'lgb_optuna'\n",
    "feature_name = 'feature'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "feature_file = feature_dir / f'{feature_name}.csv'\n",
    "p_val_file = val_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
    "sub_file = sub_dir / f'{model_name}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>redshift</th>\n",
       "      <th>dered_u</th>\n",
       "      <th>dered_g</th>\n",
       "      <th>dered_r</th>\n",
       "      <th>dered_i</th>\n",
       "      <th>dered_z</th>\n",
       "      <th>nObserve</th>\n",
       "      <th>airmass_u</th>\n",
       "      <th>class</th>\n",
       "      <th>d_dered_u</th>\n",
       "      <th>d_dered_g</th>\n",
       "      <th>d_dered_r</th>\n",
       "      <th>d_dered_i</th>\n",
       "      <th>d_dered_z</th>\n",
       "      <th>d_dered_ig</th>\n",
       "      <th>d_dered_zg</th>\n",
       "      <th>d_dered_rz</th>\n",
       "      <th>d_dered_iz</th>\n",
       "      <th>d_obs_det</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.9396</td>\n",
       "      <td>-8.1086e-05</td>\n",
       "      <td>23.1243</td>\n",
       "      <td>20.2578</td>\n",
       "      <td>18.9551</td>\n",
       "      <td>17.6321</td>\n",
       "      <td>16.9089</td>\n",
       "      <td>2.9444</td>\n",
       "      <td>1.1898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1397</td>\n",
       "      <td>-0.0790</td>\n",
       "      <td>-0.0544</td>\n",
       "      <td>-0.0403</td>\n",
       "      <td>-0.0307</td>\n",
       "      <td>-2.6257</td>\n",
       "      <td>-3.3488</td>\n",
       "      <td>2.0462</td>\n",
       "      <td>0.7232</td>\n",
       "      <td>-15.0556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.1689</td>\n",
       "      <td>4.5061e-03</td>\n",
       "      <td>14.9664</td>\n",
       "      <td>14.0045</td>\n",
       "      <td>13.4114</td>\n",
       "      <td>13.2363</td>\n",
       "      <td>13.1347</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>1.2533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0857</td>\n",
       "      <td>-0.0574</td>\n",
       "      <td>-0.0410</td>\n",
       "      <td>-0.0322</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>-0.7683</td>\n",
       "      <td>-0.8698</td>\n",
       "      <td>0.2767</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>-0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.3500</td>\n",
       "      <td>4.7198e-04</td>\n",
       "      <td>16.6076</td>\n",
       "      <td>15.6866</td>\n",
       "      <td>15.4400</td>\n",
       "      <td>15.3217</td>\n",
       "      <td>15.2961</td>\n",
       "      <td>1.0986</td>\n",
       "      <td>1.0225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1787</td>\n",
       "      <td>-0.1388</td>\n",
       "      <td>-0.0963</td>\n",
       "      <td>-0.0718</td>\n",
       "      <td>-0.0540</td>\n",
       "      <td>-0.3649</td>\n",
       "      <td>-0.3905</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>-0.9014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.6346</td>\n",
       "      <td>5.8143e-06</td>\n",
       "      <td>25.3536</td>\n",
       "      <td>20.9947</td>\n",
       "      <td>20.0873</td>\n",
       "      <td>19.7947</td>\n",
       "      <td>19.5552</td>\n",
       "      <td>1.6094</td>\n",
       "      <td>1.2054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.3070</td>\n",
       "      <td>-0.1941</td>\n",
       "      <td>-0.1339</td>\n",
       "      <td>-0.1003</td>\n",
       "      <td>-0.0795</td>\n",
       "      <td>-1.2000</td>\n",
       "      <td>-1.4395</td>\n",
       "      <td>0.5321</td>\n",
       "      <td>0.2395</td>\n",
       "      <td>-1.3906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.9826</td>\n",
       "      <td>-3.3247e-05</td>\n",
       "      <td>23.7714</td>\n",
       "      <td>20.4338</td>\n",
       "      <td>18.8630</td>\n",
       "      <td>18.1903</td>\n",
       "      <td>17.8759</td>\n",
       "      <td>2.6391</td>\n",
       "      <td>1.1939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6820</td>\n",
       "      <td>-0.2653</td>\n",
       "      <td>-0.1794</td>\n",
       "      <td>-0.1339</td>\n",
       "      <td>-0.1067</td>\n",
       "      <td>-2.2436</td>\n",
       "      <td>-2.5579</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.3144</td>\n",
       "      <td>-9.3609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          z    redshift  dered_u  dered_g  dered_r  dered_i  dered_z  \\\n",
       "id                                                                     \n",
       "0   16.9396 -8.1086e-05  23.1243  20.2578  18.9551  17.6321  16.9089   \n",
       "1   13.1689  4.5061e-03  14.9664  14.0045  13.4114  13.2363  13.1347   \n",
       "2   15.3500  4.7198e-04  16.6076  15.6866  15.4400  15.3217  15.2961   \n",
       "3   19.6346  5.8143e-06  25.3536  20.9947  20.0873  19.7947  19.5552   \n",
       "4   17.9826 -3.3247e-05  23.7714  20.4338  18.8630  18.1903  17.8759   \n",
       "\n",
       "    nObserve  airmass_u  class  d_dered_u  d_dered_g  d_dered_r  d_dered_i  \\\n",
       "id                                                                           \n",
       "0     2.9444     1.1898    0.0    -0.1397    -0.0790    -0.0544    -0.0403   \n",
       "1     0.6931     1.2533    1.0    -0.0857    -0.0574    -0.0410    -0.0322   \n",
       "2     1.0986     1.0225    0.0    -0.1787    -0.1388    -0.0963    -0.0718   \n",
       "3     1.6094     1.2054    0.0    -0.3070    -0.1941    -0.1339    -0.1003   \n",
       "4     2.6391     1.1939    0.0    -0.6820    -0.2653    -0.1794    -0.1339   \n",
       "\n",
       "    d_dered_z  d_dered_ig  d_dered_zg  d_dered_rz  d_dered_iz  d_obs_det  \n",
       "id                                                                        \n",
       "0     -0.0307     -2.6257     -3.3488      2.0462      0.7232   -15.0556  \n",
       "1     -0.0343     -0.7683     -0.8698      0.2767      0.1016    -0.3069  \n",
       "2     -0.0540     -0.3649     -0.3905      0.1440      0.0257    -0.9014  \n",
       "3     -0.0795     -1.2000     -1.4395      0.5321      0.2395    -1.3906  \n",
       "4     -0.1067     -2.2436     -2.5579      0.9871      0.3144    -9.3609  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(feature_file, index_col=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320000,) (320000, 19) (80000, 19)\n"
     ]
    }
   ],
   "source": [
    "y = df[target_col].values[:320000]\n",
    "df.drop(target_col, axis=1, inplace=True)\n",
    "trn = df.iloc[:320000].values\n",
    "tst = df.iloc[320000:].values\n",
    "feature_name = df.columns.tolist()\n",
    "print(y.shape, trn.shape, tst.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn, X_val, y_trn, y_val = train_test_split(trn, y, test_size=.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"num_class\": 3,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"subsample_freq\": 1,\n",
    "    \"lambda_l1\": 0.,\n",
    "    \"lambda_l2\": 0.,\n",
    "    \"random_state\": seed,\n",
    "    \"n_jobs\": -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-18 18:51:32,120]\u001b[0m A new study created in memory with name: no-name-e725064a-efce-48e6-ab35-14b2b6548a7d\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.170962:  14%|#4        | 1/7 [00:06<00:38,  6.39s/it]\u001b[32m[I 2021-01-18 18:51:38,519]\u001b[0m Trial 0 finished with value: 0.17096175636534075 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.17096175636534075.\u001b[0m\n",
      "feature_fraction, val_score: 0.170962:  14%|#4        | 1/7 [00:06<00:38,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's multi_logloss: 0.158753\tvalid_1's multi_logloss: 0.170962\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.169923:  29%|##8       | 2/7 [00:13<00:35,  7.06s/it]\u001b[32m[I 2021-01-18 18:51:46,049]\u001b[0m Trial 1 finished with value: 0.16992265061997341 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.16992265061997341.\u001b[0m\n",
      "feature_fraction, val_score: 0.169923:  29%|##8       | 2/7 [00:13<00:35,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's multi_logloss: 0.154919\tvalid_1's multi_logloss: 0.170396\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's multi_logloss: 0.156424\tvalid_1's multi_logloss: 0.169923\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.169923:  43%|####2     | 3/7 [00:19<00:26,  6.51s/it]\u001b[32m[I 2021-01-18 18:51:51,901]\u001b[0m Trial 2 finished with value: 0.17067186190305791 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.16992265061997341.\u001b[0m\n",
      "feature_fraction, val_score: 0.169923:  43%|####2     | 3/7 [00:19<00:26,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's multi_logloss: 0.158623\tvalid_1's multi_logloss: 0.170672\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.158717\tvalid_1's multi_logloss: 0.17132\n",
      "[200]\tvalid_0's multi_logloss: 0.143188\tvalid_1's multi_logloss: 0.166106\n",
      "[300]\tvalid_0's multi_logloss: 0.133515\tvalid_1's multi_logloss: 0.164868\n",
      "[400]\tvalid_0's multi_logloss: 0.125581\tvalid_1's multi_logloss: 0.164113\n",
      "Early stopping, best iteration is:\n",
      "[440]\tvalid_0's multi_logloss: 0.122699\tvalid_1's multi_logloss: 0.163875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.163875:  57%|#####7    | 4/7 [00:43<00:40, 13.35s/it]\u001b[32m[I 2021-01-18 18:52:15,746]\u001b[0m Trial 3 finished with value: 0.1638750687578181 and parameters: {'feature_fraction': 0.5}. Best is trial 3 with value: 0.1638750687578181.\u001b[0m\n",
      "feature_fraction, val_score: 0.163875:  57%|#####7    | 4/7 [00:43<00:40, 13.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.155774\tvalid_1's multi_logloss: 0.169529\n",
      "[200]\tvalid_0's multi_logloss: 0.141269\tvalid_1's multi_logloss: 0.165328\n",
      "[300]\tvalid_0's multi_logloss: 0.13149\tvalid_1's multi_logloss: 0.164003\n",
      "[400]\tvalid_0's multi_logloss: 0.123577\tvalid_1's multi_logloss: 0.163539\n",
      "Early stopping, best iteration is:\n",
      "[390]\tvalid_0's multi_logloss: 0.124258\tvalid_1's multi_logloss: 0.163535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.163535:  71%|#######1  | 5/7 [01:03<00:31, 15.75s/it]\u001b[32m[I 2021-01-18 18:52:35,743]\u001b[0m Trial 4 finished with value: 0.16353543107276616 and parameters: {'feature_fraction': 0.7}. Best is trial 4 with value: 0.16353543107276616.\u001b[0m\n",
      "feature_fraction, val_score: 0.163535:  71%|#######1  | 5/7 [01:03<00:31, 15.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.157483\tvalid_1's multi_logloss: 0.170786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.163535:  86%|########5 | 6/7 [01:09<00:12, 12.48s/it]\u001b[32m[I 2021-01-18 18:52:41,866]\u001b[0m Trial 5 finished with value: 0.1706641175640348 and parameters: {'feature_fraction': 0.6}. Best is trial 4 with value: 0.16353543107276616.\u001b[0m\n",
      "feature_fraction, val_score: 0.163535:  86%|########5 | 6/7 [01:09<00:12, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's multi_logloss: 0.157261\tvalid_1's multi_logloss: 0.170664\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.16272\tvalid_1's multi_logloss: 0.174574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.163535: 100%|##########| 7/7 [01:18<00:00, 11.11s/it]\u001b[32m[I 2021-01-18 18:52:50,166]\u001b[0m Trial 6 finished with value: 0.17008600818295697 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.16353543107276616.\u001b[0m\n",
      "feature_fraction, val_score: 0.163535: 100%|##########| 7/7 [01:18<00:00, 11.15s/it]\n",
      "num_leaves, val_score: 0.163535:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's multi_logloss: 0.153295\tvalid_1's multi_logloss: 0.170086\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.156324\tvalid_1's multi_logloss: 0.169626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.163535:   5%|5         | 1/20 [00:07<02:16,  7.18s/it]\u001b[32m[I 2021-01-18 18:52:57,350]\u001b[0m Trial 7 finished with value: 0.16893107292783988 and parameters: {'num_leaves': 30}. Best is trial 7 with value: 0.16893107292783988.\u001b[0m\n",
      "num_leaves, val_score: 0.163535:   5%|5         | 1/20 [00:07<02:16,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's multi_logloss: 0.154271\tvalid_1's multi_logloss: 0.168931\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.117666\tvalid_1's multi_logloss: 0.163302\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's multi_logloss: 0.109819\tvalid_1's multi_logloss: 0.162984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162984:  10%|#         | 2/20 [00:19<02:59, 10.00s/it]\u001b[32m[I 2021-01-18 18:53:09,323]\u001b[0m Trial 8 finished with value: 0.16298364123118517 and parameters: {'num_leaves': 144}. Best is trial 8 with value: 0.16298364123118517.\u001b[0m\n",
      "num_leaves, val_score: 0.162984:  10%|#         | 2/20 [00:19<02:59, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.187751\tvalid_1's multi_logloss: 0.19218\n",
      "[200]\tvalid_0's multi_logloss: 0.171533\tvalid_1's multi_logloss: 0.178355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162984:  15%|#5        | 3/20 [00:31<03:05, 10.89s/it]\u001b[32m[I 2021-01-18 18:53:21,274]\u001b[0m Trial 9 finished with value: 0.17667085475848562 and parameters: {'num_leaves': 8}. Best is trial 8 with value: 0.16298364123118517.\u001b[0m\n",
      "num_leaves, val_score: 0.162984:  15%|#5        | 3/20 [00:31<03:05, 10.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's multi_logloss: 0.168893\tvalid_1's multi_logloss: 0.176671\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.121639\tvalid_1's multi_logloss: 0.163396\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's multi_logloss: 0.114445\tvalid_1's multi_logloss: 0.163075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162984:  20%|##        | 4/20 [00:40<02:45, 10.37s/it]\u001b[32m[I 2021-01-18 18:53:30,860]\u001b[0m Trial 10 finished with value: 0.16307472213970875 and parameters: {'num_leaves': 127}. Best is trial 8 with value: 0.16298364123118517.\u001b[0m\n",
      "num_leaves, val_score: 0.162984:  20%|##        | 4/20 [00:40<02:45, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.0993984\tvalid_1's multi_logloss: 0.162652\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's multi_logloss: 0.0990076\tvalid_1's multi_logloss: 0.162646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162646:  25%|##5       | 5/20 [00:50<02:34, 10.31s/it]\u001b[32m[I 2021-01-18 18:53:41,056]\u001b[0m Trial 11 finished with value: 0.16264611304413387 and parameters: {'num_leaves': 234}. Best is trial 11 with value: 0.16264611304413387.\u001b[0m\n",
      "num_leaves, val_score: 0.162646:  25%|##5       | 5/20 [00:50<02:34, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.113822\tvalid_1's multi_logloss: 0.162953\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's multi_logloss: 0.110929\tvalid_1's multi_logloss: 0.162714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162646:  30%|###       | 6/20 [01:00<02:22, 10.21s/it]\u001b[32m[I 2021-01-18 18:53:51,057]\u001b[0m Trial 12 finished with value: 0.16271391361208473 and parameters: {'num_leaves': 161}. Best is trial 11 with value: 0.16264611304413387.\u001b[0m\n",
      "num_leaves, val_score: 0.162646:  30%|###       | 6/20 [01:00<02:22, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.133589\tvalid_1's multi_logloss: 0.164723\n",
      "[200]\tvalid_0's multi_logloss: 0.111739\tvalid_1's multi_logloss: 0.163411\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's multi_logloss: 0.110495\tvalid_1's multi_logloss: 0.163343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162646:  35%|###5      | 7/20 [01:15<02:31, 11.68s/it]\u001b[32m[I 2021-01-18 18:54:05,781]\u001b[0m Trial 13 finished with value: 0.16334335062172392 and parameters: {'num_leaves': 85}. Best is trial 11 with value: 0.16264611304413387.\u001b[0m\n",
      "num_leaves, val_score: 0.162646:  35%|###5      | 7/20 [01:15<02:31, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.103316\tvalid_1's multi_logloss: 0.163046\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's multi_logloss: 0.102537\tvalid_1's multi_logloss: 0.162995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162646:  40%|####      | 8/20 [01:26<02:15, 11.30s/it]\u001b[32m[I 2021-01-18 18:54:16,247]\u001b[0m Trial 14 finished with value: 0.16299457408051773 and parameters: {'num_leaves': 213}. Best is trial 11 with value: 0.16264611304413387.\u001b[0m\n",
      "num_leaves, val_score: 0.162646:  40%|####      | 8/20 [01:26<02:15, 11.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.170732\tvalid_1's multi_logloss: 0.178284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162646:  45%|####5     | 9/20 [01:33<01:51, 10.13s/it]\u001b[32m[I 2021-01-18 18:54:23,820]\u001b[0m Trial 15 finished with value: 0.17404134762856335 and parameters: {'num_leaves': 15}. Best is trial 11 with value: 0.16264611304413387.\u001b[0m\n",
      "num_leaves, val_score: 0.162646:  45%|####5     | 9/20 [01:33<01:51, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's multi_logloss: 0.164505\tvalid_1's multi_logloss: 0.174041\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.101908\tvalid_1's multi_logloss: 0.162748\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 0.0979865\tvalid_1's multi_logloss: 0.162627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162627:  50%|#####     | 10/20 [01:44<01:42, 10.20s/it]\u001b[32m[I 2021-01-18 18:54:34,188]\u001b[0m Trial 16 finished with value: 0.16262722641587593 and parameters: {'num_leaves': 218}. Best is trial 16 with value: 0.16262722641587593.\u001b[0m\n",
      "num_leaves, val_score: 0.162627:  50%|#####     | 10/20 [01:44<01:42, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.107054\tvalid_1's multi_logloss: 0.163019\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 0.0995235\tvalid_1's multi_logloss: 0.162871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162627:  55%|#####5    | 11/20 [04:18<08:10, 54.50s/it]\u001b[32m[I 2021-01-18 18:57:09,139]\u001b[0m Trial 17 finished with value: 0.16287119776152736 and parameters: {'num_leaves': 193}. Best is trial 16 with value: 0.16262722641587593.\u001b[0m\n",
      "num_leaves, val_score: 0.162627:  55%|#####5    | 11/20 [04:18<08:10, 54.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.0961028\tvalid_1's multi_logloss: 0.16337\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's multi_logloss: 0.0996437\tvalid_1's multi_logloss: 0.163274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162627:  60%|######    | 12/20 [04:30<05:32, 41.52s/it]\u001b[32m[I 2021-01-18 18:57:20,947]\u001b[0m Trial 18 finished with value: 0.16327405689615843 and parameters: {'num_leaves': 252}. Best is trial 16 with value: 0.16262722641587593.\u001b[0m\n",
      "num_leaves, val_score: 0.162627:  60%|######    | 12/20 [04:30<05:32, 41.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.0961028\tvalid_1's multi_logloss: 0.16337\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's multi_logloss: 0.0996437\tvalid_1's multi_logloss: 0.163274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162627:  65%|######5   | 13/20 [04:39<03:41, 31.64s/it]\u001b[32m[I 2021-01-18 18:57:29,870]\u001b[0m Trial 19 finished with value: 0.16327405689615843 and parameters: {'num_leaves': 252}. Best is trial 16 with value: 0.16262722641587593.\u001b[0m\n",
      "num_leaves, val_score: 0.162627:  65%|######5   | 13/20 [04:39<03:41, 31.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.102624\tvalid_1's multi_logloss: 0.16293\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's multi_logloss: 0.0991651\tvalid_1's multi_logloss: 0.162811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162627:  70%|#######   | 14/20 [06:59<06:26, 64.41s/it]\u001b[32m[I 2021-01-18 18:59:50,010]\u001b[0m Trial 20 finished with value: 0.16281093525105986 and parameters: {'num_leaves': 216}. Best is trial 16 with value: 0.16262722641587593.\u001b[0m\n",
      "num_leaves, val_score: 0.162627:  70%|#######   | 14/20 [06:59<06:26, 64.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.0961258\tvalid_1's multi_logloss: 0.163032\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's multi_logloss: 0.0997378\tvalid_1's multi_logloss: 0.162945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162627:  75%|#######5  | 15/20 [07:09<03:59, 47.82s/it]\u001b[32m[I 2021-01-18 18:59:59,382]\u001b[0m Trial 21 finished with value: 0.1629453551367762 and parameters: {'num_leaves': 253}. Best is trial 16 with value: 0.16262722641587593.\u001b[0m\n",
      "num_leaves, val_score: 0.162627:  75%|#######5  | 15/20 [07:09<03:59, 47.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.108901\tvalid_1's multi_logloss: 0.162828\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.103376\tvalid_1's multi_logloss: 0.162618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162618:  80%|########  | 16/20 [07:18<02:25, 36.26s/it]\u001b[32m[I 2021-01-18 19:00:08,800]\u001b[0m Trial 22 finished with value: 0.16261819224273638 and parameters: {'num_leaves': 184}. Best is trial 22 with value: 0.16261819224273638.\u001b[0m\n",
      "num_leaves, val_score: 0.162618:  80%|########  | 16/20 [07:18<02:25, 36.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110482\tvalid_1's multi_logloss: 0.162693\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.105165\tvalid_1's multi_logloss: 0.162498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162498:  85%|########5 | 17/20 [07:29<01:25, 28.52s/it]\u001b[32m[I 2021-01-18 19:00:19,304]\u001b[0m Trial 23 finished with value: 0.16249807675530126 and parameters: {'num_leaves': 177}. Best is trial 23 with value: 0.16249807675530126.\u001b[0m\n",
      "num_leaves, val_score: 0.162498:  85%|########5 | 17/20 [07:29<01:25, 28.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110482\tvalid_1's multi_logloss: 0.162693\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.105165\tvalid_1's multi_logloss: 0.162498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162498:  90%|######### | 18/20 [07:38<00:45, 22.88s/it]\u001b[32m[I 2021-01-18 19:00:29,078]\u001b[0m Trial 24 finished with value: 0.16249807675530126 and parameters: {'num_leaves': 177}. Best is trial 23 with value: 0.16249807675530126.\u001b[0m\n",
      "num_leaves, val_score: 0.162498:  90%|######### | 18/20 [07:38<00:45, 22.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.131332\tvalid_1's multi_logloss: 0.163987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162498:  95%|#########5| 19/20 [07:49<00:19, 19.07s/it]\u001b[32m[I 2021-01-18 19:00:39,256]\u001b[0m Trial 25 finished with value: 0.16315624199205633 and parameters: {'num_leaves': 92}. Best is trial 23 with value: 0.16249807675530126.\u001b[0m\n",
      "num_leaves, val_score: 0.162498:  95%|#########5| 19/20 [07:49<00:19, 19.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's multi_logloss: 0.117694\tvalid_1's multi_logloss: 0.163156\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110396\tvalid_1's multi_logloss: 0.163379\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's multi_logloss: 0.103532\tvalid_1's multi_logloss: 0.163152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162498: 100%|##########| 20/20 [07:59<00:00, 16.37s/it]\u001b[32m[I 2021-01-18 19:00:49,337]\u001b[0m Trial 26 finished with value: 0.163152103066861 and parameters: {'num_leaves': 176}. Best is trial 23 with value: 0.16249807675530126.\u001b[0m\n",
      "num_leaves, val_score: 0.162498: 100%|##########| 20/20 [07:59<00:00, 23.96s/it]\n",
      "bagging, val_score: 0.162498:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110183\tvalid_1's multi_logloss: 0.162972\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 0.102822\tvalid_1's multi_logloss: 0.162799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162498:  10%|#         | 1/10 [00:12<01:49, 12.11s/it]\u001b[32m[I 2021-01-18 19:01:01,456]\u001b[0m Trial 27 finished with value: 0.16279937456674567 and parameters: {'bagging_fraction': 0.9648922824330194, 'bagging_freq': 2}. Best is trial 27 with value: 0.16279937456674567.\u001b[0m\n",
      "bagging, val_score: 0.162498:  10%|#         | 1/10 [00:12<01:49, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110566\tvalid_1's multi_logloss: 0.163657\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.107077\tvalid_1's multi_logloss: 0.163552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162498:  20%|##        | 2/10 [00:21<01:25, 10.67s/it]\u001b[32m[I 2021-01-18 19:01:11,110]\u001b[0m Trial 28 finished with value: 0.1635523469289637 and parameters: {'bagging_fraction': 0.655107179195906, 'bagging_freq': 1}. Best is trial 27 with value: 0.16279937456674567.\u001b[0m\n",
      "bagging, val_score: 0.162498:  20%|##        | 2/10 [00:21<01:25, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.111741\tvalid_1's multi_logloss: 0.164558\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.111741\tvalid_1's multi_logloss: 0.164558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162498:  30%|###       | 3/10 [00:32<01:14, 10.67s/it]\u001b[32m[I 2021-01-18 19:01:21,795]\u001b[0m Trial 29 finished with value: 0.16455813811083198 and parameters: {'bagging_fraction': 0.45251870857852394, 'bagging_freq': 1}. Best is trial 27 with value: 0.16279937456674567.\u001b[0m\n",
      "bagging, val_score: 0.162498:  30%|###       | 3/10 [00:32<01:14, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110357\tvalid_1's multi_logloss: 0.163002\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 0.106553\tvalid_1's multi_logloss: 0.162835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162498:  40%|####      | 4/10 [00:43<01:04, 10.83s/it]\u001b[32m[I 2021-01-18 19:01:32,860]\u001b[0m Trial 30 finished with value: 0.16283549789606996 and parameters: {'bagging_fraction': 0.8996307233195937, 'bagging_freq': 7}. Best is trial 27 with value: 0.16279937456674567.\u001b[0m\n",
      "bagging, val_score: 0.162498:  40%|####      | 4/10 [00:43<01:04, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110253\tvalid_1's multi_logloss: 0.163147\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.106837\tvalid_1's multi_logloss: 0.163044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162498:  50%|#####     | 5/10 [00:53<00:53, 10.62s/it]\u001b[32m[I 2021-01-18 19:01:43,116]\u001b[0m Trial 31 finished with value: 0.16304406848246356 and parameters: {'bagging_fraction': 0.8253604599876216, 'bagging_freq': 1}. Best is trial 27 with value: 0.16279937456674567.\u001b[0m\n",
      "bagging, val_score: 0.162498:  50%|#####     | 5/10 [00:53<00:53, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110165\tvalid_1's multi_logloss: 0.163031\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.104711\tvalid_1's multi_logloss: 0.162861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162498:  60%|######    | 6/10 [01:05<00:43, 10.96s/it]\u001b[32m[I 2021-01-18 19:01:54,730]\u001b[0m Trial 32 finished with value: 0.1628612201912957 and parameters: {'bagging_fraction': 0.9489552616919207, 'bagging_freq': 6}. Best is trial 27 with value: 0.16279937456674567.\u001b[0m\n",
      "bagging, val_score: 0.162498:  60%|######    | 6/10 [01:05<00:43, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.11018\tvalid_1's multi_logloss: 0.163455\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's multi_logloss: 0.10858\tvalid_1's multi_logloss: 0.163405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162498:  70%|#######   | 7/10 [01:15<00:32, 10.81s/it]\u001b[32m[I 2021-01-18 19:02:05,239]\u001b[0m Trial 33 finished with value: 0.16340496616130368 and parameters: {'bagging_fraction': 0.8432873300803907, 'bagging_freq': 6}. Best is trial 27 with value: 0.16279937456674567.\u001b[0m\n",
      "bagging, val_score: 0.162498:  70%|#######   | 7/10 [01:15<00:32, 10.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.111669\tvalid_1's multi_logloss: 0.164632\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's multi_logloss: 0.114212\tvalid_1's multi_logloss: 0.164589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162498:  80%|########  | 8/10 [01:24<00:20, 10.24s/it]\u001b[32m[I 2021-01-18 19:02:14,239]\u001b[0m Trial 34 finished with value: 0.16458893644091482 and parameters: {'bagging_fraction': 0.5239739458236881, 'bagging_freq': 3}. Best is trial 27 with value: 0.16279937456674567.\u001b[0m\n",
      "bagging, val_score: 0.162498:  80%|########  | 8/10 [01:24<00:20, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.112391\tvalid_1's multi_logloss: 0.164756\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.112391\tvalid_1's multi_logloss: 0.164756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162498:  90%|######### | 9/10 [01:34<00:10, 10.18s/it]\u001b[32m[I 2021-01-18 19:02:24,297]\u001b[0m Trial 35 finished with value: 0.16475552175967637 and parameters: {'bagging_fraction': 0.4191643165113175, 'bagging_freq': 1}. Best is trial 27 with value: 0.16279937456674567.\u001b[0m\n",
      "bagging, val_score: 0.162498:  90%|######### | 9/10 [01:34<00:10, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.109912\tvalid_1's multi_logloss: 0.162818\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's multi_logloss: 0.111143\tvalid_1's multi_logloss: 0.162776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162498: 100%|##########| 10/10 [01:44<00:00, 10.00s/it]\u001b[32m[I 2021-01-18 19:02:33,887]\u001b[0m Trial 36 finished with value: 0.1627764280263277 and parameters: {'bagging_fraction': 0.9361567611866247, 'bagging_freq': 4}. Best is trial 36 with value: 0.1627764280263277.\u001b[0m\n",
      "bagging, val_score: 0.162498: 100%|##########| 10/10 [01:44<00:00, 10.45s/it]\n",
      "feature_fraction_stage2, val_score: 0.162498:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.111294\tvalid_1's multi_logloss: 0.163262\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.107954\tvalid_1's multi_logloss: 0.163061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.162498:  17%|#6        | 1/6 [00:09<00:46,  9.37s/it]\u001b[32m[I 2021-01-18 19:02:43,268]\u001b[0m Trial 37 finished with value: 0.1630614610864373 and parameters: {'feature_fraction': 0.652}. Best is trial 37 with value: 0.1630614610864373.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.162498:  17%|#6        | 1/6 [00:09<00:46,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.111294\tvalid_1's multi_logloss: 0.163262\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.107954\tvalid_1's multi_logloss: 0.163061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.162498:  33%|###3      | 2/6 [00:18<00:37,  9.35s/it]\u001b[32m[I 2021-01-18 19:02:52,610]\u001b[0m Trial 38 finished with value: 0.1630614610864373 and parameters: {'feature_fraction': 0.62}. Best is trial 37 with value: 0.1630614610864373.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.162498:  33%|###3      | 2/6 [00:18<00:37,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.109866\tvalid_1's multi_logloss: 0.162736\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's multi_logloss: 0.10579\tvalid_1's multi_logloss: 0.162643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.162498:  50%|#####     | 3/6 [00:28<00:28,  9.35s/it]\u001b[32m[I 2021-01-18 19:03:01,961]\u001b[0m Trial 39 finished with value: 0.162642597678508 and parameters: {'feature_fraction': 0.716}. Best is trial 39 with value: 0.162642597678508.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.162498:  50%|#####     | 3/6 [00:28<00:28,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110482\tvalid_1's multi_logloss: 0.162693\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.105165\tvalid_1's multi_logloss: 0.162498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.162498:  67%|######6   | 4/6 [00:38<00:19,  9.60s/it]\u001b[32m[I 2021-01-18 19:03:11,947]\u001b[0m Trial 40 finished with value: 0.16249807675530126 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 40 with value: 0.16249807675530126.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.162498:  67%|######6   | 4/6 [00:38<00:19,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.109866\tvalid_1's multi_logloss: 0.162736\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's multi_logloss: 0.10579\tvalid_1's multi_logloss: 0.162643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.162498:  83%|########3 | 5/6 [00:47<00:09,  9.51s/it]\u001b[32m[I 2021-01-18 19:03:21,298]\u001b[0m Trial 41 finished with value: 0.162642597678508 and parameters: {'feature_fraction': 0.748}. Best is trial 40 with value: 0.16249807675530126.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.162498:  83%|########3 | 5/6 [00:47<00:09,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.10948\tvalid_1's multi_logloss: 0.163027\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's multi_logloss: 0.110942\tvalid_1's multi_logloss: 0.162971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.162498: 100%|##########| 6/6 [00:56<00:00,  9.32s/it]\u001b[32m[I 2021-01-18 19:03:30,243]\u001b[0m Trial 42 finished with value: 0.16297094373830245 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 40 with value: 0.16249807675530126.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.162498: 100%|##########| 6/6 [00:56<00:00,  9.39s/it]\n",
      "regularization_factors, val_score: 0.162498:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110493\tvalid_1's multi_logloss: 0.163065\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's multi_logloss: 0.10772\tvalid_1's multi_logloss: 0.16283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162498:   5%|5         | 1/20 [00:09<03:00,  9.50s/it]\u001b[32m[I 2021-01-18 19:03:39,744]\u001b[0m Trial 43 finished with value: 0.16283035990904993 and parameters: {'lambda_l1': 5.487756570320648e-07, 'lambda_l2': 0.000246014355527248}. Best is trial 43 with value: 0.16283035990904993.\u001b[0m\n",
      "regularization_factors, val_score: 0.162498:   5%|5         | 1/20 [00:09<03:00,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.110506\tvalid_1's multi_logloss: 0.16313\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's multi_logloss: 0.107617\tvalid_1's multi_logloss: 0.162926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162498:  10%|#         | 2/20 [00:18<02:50,  9.47s/it]\u001b[32m[I 2021-01-18 19:03:49,191]\u001b[0m Trial 44 finished with value: 0.1629259483410696 and parameters: {'lambda_l1': 5.259549433368151e-06, 'lambda_l2': 0.027993063212669138}. Best is trial 43 with value: 0.16283035990904993.\u001b[0m\n",
      "regularization_factors, val_score: 0.162498:  10%|#         | 2/20 [00:18<02:50,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.111444\tvalid_1's multi_logloss: 0.162819\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 0.107719\tvalid_1's multi_logloss: 0.162641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162498:  15%|#5        | 3/20 [00:28<02:45,  9.73s/it]\u001b[32m[I 2021-01-18 19:03:59,245]\u001b[0m Trial 45 finished with value: 0.16264051594764375 and parameters: {'lambda_l1': 0.27906657583371636, 'lambda_l2': 5.382827551719569e-06}. Best is trial 45 with value: 0.16264051594764375.\u001b[0m\n",
      "regularization_factors, val_score: 0.162498:  15%|#5        | 3/20 [00:28<02:45,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110381\tvalid_1's multi_logloss: 0.163201\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.107108\tvalid_1's multi_logloss: 0.163074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162498:  20%|##        | 4/20 [00:38<02:34,  9.66s/it]\u001b[32m[I 2021-01-18 19:04:08,789]\u001b[0m Trial 46 finished with value: 0.16307447942409392 and parameters: {'lambda_l1': 0.0010360030423603418, 'lambda_l2': 0.0024428442409380226}. Best is trial 45 with value: 0.16264051594764375.\u001b[0m\n",
      "regularization_factors, val_score: 0.162498:  20%|##        | 4/20 [00:38<02:34,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110655\tvalid_1's multi_logloss: 0.163201\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's multi_logloss: 0.109948\tvalid_1's multi_logloss: 0.163188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162498:  25%|##5       | 5/20 [00:48<02:27,  9.80s/it]\u001b[32m[I 2021-01-18 19:04:18,849]\u001b[0m Trial 47 finished with value: 0.16318792668266158 and parameters: {'lambda_l1': 4.5818305108290255e-07, 'lambda_l2': 1.5596255959331835e-05}. Best is trial 45 with value: 0.16264051594764375.\u001b[0m\n",
      "regularization_factors, val_score: 0.162498:  25%|##5       | 5/20 [00:48<02:27,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110216\tvalid_1's multi_logloss: 0.16327\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's multi_logloss: 0.108392\tvalid_1's multi_logloss: 0.163205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162498:  30%|###       | 6/20 [03:02<12:08, 52.01s/it]\u001b[32m[I 2021-01-18 19:06:32,783]\u001b[0m Trial 48 finished with value: 0.16320495190642606 and parameters: {'lambda_l1': 0.0007831899987854707, 'lambda_l2': 0.0019026346513676814}. Best is trial 45 with value: 0.16264051594764375.\u001b[0m\n",
      "regularization_factors, val_score: 0.162498:  30%|###       | 6/20 [03:02<12:08, 52.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110503\tvalid_1's multi_logloss: 0.163207\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 0.106785\tvalid_1's multi_logloss: 0.163014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162498:  35%|###5      | 7/20 [03:12<08:17, 38.24s/it]\u001b[32m[I 2021-01-18 19:06:42,673]\u001b[0m Trial 49 finished with value: 0.1630140982228141 and parameters: {'lambda_l1': 1.0090411664201754e-06, 'lambda_l2': 8.949288133679309e-05}. Best is trial 45 with value: 0.16264051594764375.\u001b[0m\n",
      "regularization_factors, val_score: 0.162498:  35%|###5      | 7/20 [03:12<08:17, 38.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.112723\tvalid_1's multi_logloss: 0.162464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 0.105381\tvalid_1's multi_logloss: 0.162182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162182:  40%|####      | 8/20 [03:23<05:54, 29.50s/it]\u001b[32m[I 2021-01-18 19:06:53,460]\u001b[0m Trial 50 finished with value: 0.16218193309447348 and parameters: {'lambda_l1': 0.6442681371131758, 'lambda_l2': 1.2786085216150597e-08}. Best is trial 50 with value: 0.16218193309447348.\u001b[0m\n",
      "regularization_factors, val_score: 0.162182:  40%|####      | 8/20 [03:23<05:54, 29.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.110842\tvalid_1's multi_logloss: 0.163231\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's multi_logloss: 0.108593\tvalid_1's multi_logloss: 0.16317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162182:  45%|####5     | 9/20 [03:32<04:14, 23.18s/it]\u001b[32m[I 2021-01-18 19:07:02,734]\u001b[0m Trial 51 finished with value: 0.1631697475121773 and parameters: {'lambda_l1': 0.02210763789670649, 'lambda_l2': 0.04743300151156979}. Best is trial 50 with value: 0.16218193309447348.\u001b[0m\n",
      "regularization_factors, val_score: 0.162182:  45%|####5     | 9/20 [03:32<04:14, 23.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.132796\tvalid_1's multi_logloss: 0.163598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's multi_logloss: 0.124756\tvalid_1's multi_logloss: 0.162672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162182:  50%|#####     | 10/20 [03:45<03:19, 19.94s/it]\u001b[32m[I 2021-01-18 19:07:15,433]\u001b[0m Trial 52 finished with value: 0.16267221178776015 and parameters: {'lambda_l1': 8.407649817952096, 'lambda_l2': 0.08036886374485097}. Best is trial 50 with value: 0.16218193309447348.\u001b[0m\n",
      "regularization_factors, val_score: 0.162182:  50%|#####     | 10/20 [03:45<03:19, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.127295\tvalid_1's multi_logloss: 0.162999\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's multi_logloss: 0.116384\tvalid_1's multi_logloss: 0.162273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162182:  55%|#####5    | 11/20 [03:58<02:41, 17.91s/it]\u001b[32m[I 2021-01-18 19:07:28,753]\u001b[0m Trial 53 finished with value: 0.16227291974635866 and parameters: {'lambda_l1': 5.320546859301923, 'lambda_l2': 1.701999453130838e-08}. Best is trial 50 with value: 0.16218193309447348.\u001b[0m\n",
      "regularization_factors, val_score: 0.162182:  55%|#####5    | 11/20 [03:58<02:41, 17.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.132087\tvalid_1's multi_logloss: 0.163388\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's multi_logloss: 0.117085\tvalid_1's multi_logloss: 0.162511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162182:  60%|######    | 12/20 [04:14<02:17, 17.23s/it]\u001b[32m[I 2021-01-18 19:07:44,406]\u001b[0m Trial 54 finished with value: 0.16251103560088176 and parameters: {'lambda_l1': 7.974358628240666, 'lambda_l2': 1.017284286943919e-08}. Best is trial 50 with value: 0.16218193309447348.\u001b[0m\n",
      "regularization_factors, val_score: 0.162182:  60%|######    | 12/20 [04:14<02:17, 17.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.111348\tvalid_1's multi_logloss: 0.162762\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's multi_logloss: 0.10223\tvalid_1's multi_logloss: 0.162339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162182:  65%|######5   | 13/20 [04:24<01:46, 15.20s/it]\u001b[32m[I 2021-01-18 19:07:54,940]\u001b[0m Trial 55 finished with value: 0.16233946036182642 and parameters: {'lambda_l1': 0.33160111773250395, 'lambda_l2': 1.1255724557732143e-08}. Best is trial 50 with value: 0.16218193309447348.\u001b[0m\n",
      "regularization_factors, val_score: 0.162182:  65%|######5   | 13/20 [04:24<01:46, 15.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.112022\tvalid_1's multi_logloss: 0.162041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's multi_logloss: 0.0957638\tvalid_1's multi_logloss: 0.161749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161749:  70%|#######   | 14/20 [04:37<01:27, 14.61s/it]\u001b[32m[I 2021-01-18 19:08:08,185]\u001b[0m Trial 56 finished with value: 0.16174879836713443 and parameters: {'lambda_l1': 0.5683816134509518, 'lambda_l2': 1.9164729696677358e-07}. Best is trial 56 with value: 0.16174879836713443.\u001b[0m\n",
      "regularization_factors, val_score: 0.161749:  70%|#######   | 14/20 [04:37<01:27, 14.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.110394\tvalid_1's multi_logloss: 0.162719\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.107036\tvalid_1's multi_logloss: 0.162456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161749:  75%|#######5  | 15/20 [04:47<01:05, 13.18s/it]\u001b[32m[I 2021-01-18 19:08:18,036]\u001b[0m Trial 57 finished with value: 0.16245550005492201 and parameters: {'lambda_l1': 0.028153731877743608, 'lambda_l2': 4.7111931461213864e-07}. Best is trial 56 with value: 0.16174879836713443.\u001b[0m\n",
      "regularization_factors, val_score: 0.161749:  75%|#######5  | 15/20 [04:47<01:05, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110564\tvalid_1's multi_logloss: 0.163219\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's multi_logloss: 0.104139\tvalid_1's multi_logloss: 0.163008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161749:  80%|########  | 16/20 [04:58<00:49, 12.28s/it]\u001b[32m[I 2021-01-18 19:08:28,251]\u001b[0m Trial 58 finished with value: 0.1630077465917924 and parameters: {'lambda_l1': 1.1122935887470557e-08, 'lambda_l2': 2.054488103353596e-07}. Best is trial 56 with value: 0.16174879836713443.\u001b[0m\n",
      "regularization_factors, val_score: 0.161749:  80%|########  | 16/20 [04:58<00:49, 12.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.11222\tvalid_1's multi_logloss: 0.162805\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's multi_logloss: 0.105519\tvalid_1's multi_logloss: 0.162594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161749:  85%|########5 | 17/20 [05:08<00:34, 11.64s/it]\u001b[32m[I 2021-01-18 19:08:38,406]\u001b[0m Trial 59 finished with value: 0.1625936717059594 and parameters: {'lambda_l1': 0.5514042734262611, 'lambda_l2': 3.7992799384582874e-07}. Best is trial 56 with value: 0.16174879836713443.\u001b[0m\n",
      "regularization_factors, val_score: 0.161749:  85%|########5 | 17/20 [05:08<00:34, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.110561\tvalid_1's multi_logloss: 0.163205\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's multi_logloss: 0.1083\tvalid_1's multi_logloss: 0.162997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161749:  90%|######### | 18/20 [05:17<00:22, 11.05s/it]\u001b[32m[I 2021-01-18 19:08:48,063]\u001b[0m Trial 60 finished with value: 0.1629965955601444 and parameters: {'lambda_l1': 0.023537511925986365, 'lambda_l2': 6.522204750532647e-08}. Best is trial 56 with value: 0.16174879836713443.\u001b[0m\n",
      "regularization_factors, val_score: 0.161749:  90%|######### | 18/20 [05:17<00:22, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.120318\tvalid_1's multi_logloss: 0.162665\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.115946\tvalid_1's multi_logloss: 0.162399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161749:  95%|#########5| 19/20 [05:29<00:11, 11.13s/it]\u001b[32m[I 2021-01-18 19:08:59,373]\u001b[0m Trial 61 finished with value: 0.1623985457965689 and parameters: {'lambda_l1': 1.0342337155153234, 'lambda_l2': 3.803349824563281}. Best is trial 56 with value: 0.16174879836713443.\u001b[0m\n",
      "regularization_factors, val_score: 0.161749:  95%|#########5| 19/20 [05:29<00:11, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110461\tvalid_1's multi_logloss: 0.16317\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's multi_logloss: 0.107761\tvalid_1's multi_logloss: 0.163051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161749: 100%|##########| 20/20 [05:39<00:00, 10.75s/it]\u001b[32m[I 2021-01-18 19:09:09,256]\u001b[0m Trial 62 finished with value: 0.16305132375845408 and parameters: {'lambda_l1': 5.2399820858072416e-05, 'lambda_l2': 1.7128673521585685e-06}. Best is trial 56 with value: 0.16174879836713443.\u001b[0m\n",
      "regularization_factors, val_score: 0.161749: 100%|##########| 20/20 [05:39<00:00, 16.95s/it]\n",
      "min_data_in_leaf, val_score: 0.161749:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.110718\tvalid_1's multi_logloss: 0.162483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's multi_logloss: 0.0956928\tvalid_1's multi_logloss: 0.162212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.161749:  20%|##        | 1/5 [00:13<00:53, 13.40s/it]\u001b[32m[I 2021-01-18 19:09:22,675]\u001b[0m Trial 63 finished with value: 0.16221192202677098 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.16221192202677098.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.161749:  20%|##        | 1/5 [00:13<00:53, 13.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.111148\tvalid_1's multi_logloss: 0.162781\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.105883\tvalid_1's multi_logloss: 0.162592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.161749:  40%|####      | 2/5 [00:23<00:35, 11.69s/it]\u001b[32m[I 2021-01-18 19:09:33,172]\u001b[0m Trial 64 finished with value: 0.16259198844602687 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.16221192202677098.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.161749:  40%|####      | 2/5 [00:23<00:35, 11.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.116777\tvalid_1's multi_logloss: 0.162541\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's multi_logloss: 0.111132\tvalid_1's multi_logloss: 0.162365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.161749:  60%|######    | 3/5 [00:34<00:22, 11.13s/it]\u001b[32m[I 2021-01-18 19:09:43,631]\u001b[0m Trial 65 finished with value: 0.16236496786081767 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.16221192202677098.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.161749:  60%|######    | 3/5 [00:34<00:22, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.112637\tvalid_1's multi_logloss: 0.162737\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 0.105467\tvalid_1's multi_logloss: 0.162629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.161749:  80%|########  | 4/5 [00:45<00:11, 11.09s/it]\u001b[32m[I 2021-01-18 19:09:54,662]\u001b[0m Trial 66 finished with value: 0.16262927724118542 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.16221192202677098.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.161749:  80%|########  | 4/5 [00:45<00:11, 11.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.114613\tvalid_1's multi_logloss: 0.16242\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.111458\tvalid_1's multi_logloss: 0.162244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.161749: 100%|##########| 5/5 [00:55<00:00, 10.82s/it]\u001b[32m[I 2021-01-18 19:10:05,011]\u001b[0m Trial 67 finished with value: 0.16224358648282963 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.16221192202677098.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.161749: 100%|##########| 5/5 [00:55<00:00, 11.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': 3, 'lambda_l1': 0.5683816134509518, 'lambda_l2': 1.9164729696677358e-07, 'random_state': 42, 'n_jobs': -1, 'feature_pre_filter': False, 'bagging_freq': 1, 'num_leaves': 177, 'feature_fraction': 0.7, 'bagging_fraction': 1.0, 'min_child_samples': 20, 'num_iterations': 1000, 'early_stopping_round': 10}\n",
      "  Accuracy = 0.931734375\n",
      "  Params: \n",
      "    objective: multiclass\n",
      "    metric: multi_logloss\n",
      "    num_class: 3\n",
      "    lambda_l1: 0.5683816134509518\n",
      "    lambda_l2: 1.9164729696677358e-07\n",
      "    random_state: 42\n",
      "    n_jobs: -1\n",
      "    feature_pre_filter: False\n",
      "    bagging_freq: 1\n",
      "    num_leaves: 177\n",
      "    feature_fraction: 0.7\n",
      "    bagging_fraction: 1.0\n",
      "    min_child_samples: 20\n",
      "    num_iterations: 1000\n",
      "    early_stopping_round: 10\n"
     ]
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(X_trn, label=y_trn)\n",
    "dval = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "model = lgb.train(params, dtrain, valid_sets=[dtrain, dval], \n",
    "                  verbose_eval=100, early_stopping_rounds=10)\n",
    "\n",
    "prediction = np.argmax(model.predict(X_val, num_iteration=model.best_iteration), \n",
    "                       axis=1)\n",
    "accuracy = accuracy_score(y_val, prediction)\n",
    "\n",
    "params = model.params\n",
    "print(\"Best params:\", params)\n",
    "print(\"  Accuracy = {}\".format(accuracy))\n",
    "print(\"  Params: \")\n",
    "for key, value in params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for CV #1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5683816134509518, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5683816134509518\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9164729696677358e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9164729696677358e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "training model for CV #2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5683816134509518, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5683816134509518\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9164729696677358e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9164729696677358e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "training model for CV #3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5683816134509518, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5683816134509518\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9164729696677358e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9164729696677358e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "training model for CV #4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5683816134509518, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5683816134509518\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9164729696677358e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9164729696677358e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "training model for CV #5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5683816134509518, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5683816134509518\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9164729696677358e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9164729696677358e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "p_val = np.zeros((trn.shape[0], n_class))\n",
    "p_tst = np.zeros((tst.shape[0], n_class))\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    clf = LGBMClassifier(**params)\n",
    "    clf.fit(trn[i_trn], y[i_trn],\n",
    "            eval_set=[(trn[i_val], y[i_val])],\n",
    "            eval_metric='multiclass',\n",
    "            early_stopping_rounds=10, verbose=False)\n",
    "    \n",
    "    p_val[i_val, :] = clf.predict_proba(trn[i_val])\n",
    "    p_tst += clf.predict_proba(tst) / n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.2859%\n"
     ]
    }
   ],
   "source": [
    "print(f'{accuracy_score(y, np.argmax(p_val, axis=1)) * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320000, 3) (80000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(p_val.shape, p_tst.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csv   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(p_val_file, p_val, fmt='%.6f', delimiter=',')\n",
    "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='feature'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp = pd.DataFrame({'feature': df.columns, 'importance': clf.feature_importances_})\n",
    "imp = imp.sort_values('importance').set_index('feature')\n",
    "imp.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320001</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320002</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320003</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320004</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class\n",
       "id           \n",
       "320000      0\n",
       "320001      0\n",
       "320002      0\n",
       "320003      0\n",
       "320004      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(sample_file, index_col=0)\n",
    "print(sub.shape)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320000</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320001</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320002</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320003</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320004</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class\n",
       "id           \n",
       "320000      2\n",
       "320001      0\n",
       "320002      2\n",
       "320003      0\n",
       "320004      2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[target_col] = np.argmax(p_tst, axis=1)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    40993\n",
       "0    29974\n",
       "1     9033\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[target_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(sub_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
